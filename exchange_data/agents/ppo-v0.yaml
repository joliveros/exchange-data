orderbook-ppo:
    env: orderbook-trading-v0
    run: PPO
    checkpoint_freq: 10
    checkpoint_at_end: True
    max_failures: 10000
    config:
        batch_mode: truncate_episodes
        clip_param: 0.1
        clip_rewards: False
        entropy_coeff: 0.01
        kl_coeff: 0.5
        lambda: 0.95
        num_envs_per_worker: 4
        num_gpus: 1
        num_sgd_iter: 10
        num_workers: 14
        observation_filter: NoFilter
        sample_batch_size: 100
        sgd_minibatch_size: 500
        train_batch_size: 5000
        vf_clip_param: 10.0
        vf_share_layers: true
