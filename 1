models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.163914: I tensorflow_serving/model_servers/server_core.cc:464] Adding/updating models.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.163914: I tensorflow_serving/model_servers/server_core.cc:464] Adding/updating models.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.163952: I tensorflow_serving/model_servers/server_core.cc:587]  (Re-)adding model: ZILBNB
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.163959: I tensorflow_serving/model_servers/server_core.cc:587]  (Re-)adding model: best_ZILBNB
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.163952: I tensorflow_serving/model_servers/server_core.cc:587]  (Re-)adding model: ZILBNB
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.163959: I tensorflow_serving/model_servers/server_core.cc:587]  (Re-)adding model: best_ZILBNB
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.264285: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: best_ZILBNB version: 1}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.264285: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: best_ZILBNB version: 1}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.264366: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: best_ZILBNB version: 1}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.264366: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: best_ZILBNB version: 1}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.264408: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: best_ZILBNB version: 1}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.264408: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: best_ZILBNB version: 1}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.264470: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: /best_exported_models/ZILBNB/1
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.264470: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: /best_exported_models/ZILBNB/1
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.276745: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.276745: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.276967: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: /best_exported_models/ZILBNB/1
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.276967: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: /best_exported_models/ZILBNB/1
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.277184: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.277184: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
models_model_host.1.rnmmwpelij0w@box    | To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
models_model_host.1.rnmmwpelij0w@box    | To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.279487: I external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.279487: I external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.284926: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.285432: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.284926: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.285432: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
models_model_host.1.rnmmwpelij0w@box    | pciBusID: 0000:0a:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
models_model_host.1.rnmmwpelij0w@box    | pciBusID: 0000:0a:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
models_model_host.1.rnmmwpelij0w@box    | coreClock: 1.4805GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s
models_model_host.1.rnmmwpelij0w@box    | coreClock: 1.4805GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.285502: I external/org_tensorflow/tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.285502: I external/org_tensorflow/tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.285627: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.285627: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.286065: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.286065: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.286888: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.286888: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.364665: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: ZILBNB version: 1610136623}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.364665: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: ZILBNB version: 1610136623}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.364704: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: ZILBNB version: 1610136623}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.364704: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: ZILBNB version: 1610136623}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.364718: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: ZILBNB version: 1610136623}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.364718: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: ZILBNB version: 1610136623}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.364748: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: /models/ZILBNB_export/1610136623
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.364748: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: /models/ZILBNB_export/1610136623
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.383816: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.383816: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.383874: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: /models/ZILBNB_export/1610136623
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.383874: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: /models/ZILBNB_export/1610136623
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.465412: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: ZILBNB version: 1610136569}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.465412: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: ZILBNB version: 1610136569}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.465851: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: ZILBNB version: 1610136569}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.465851: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: ZILBNB version: 1610136569}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.465992: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: ZILBNB version: 1610136569}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.465992: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: ZILBNB version: 1610136569}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.466305: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: /models/ZILBNB_export/1610136569
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.466305: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: /models/ZILBNB_export/1610136569
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.490512: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.490512: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.490637: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: /models/ZILBNB_export/1610136569
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.490637: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: /models/ZILBNB_export/1610136569
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.967689: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.967689: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.967732: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.967732: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.967741: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.967741: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.967877: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.967877: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.968252: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.968252: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.968613: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.968613: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.968948: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 120 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1)
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.968948: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 120 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1)
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.974502: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.974502: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.974881: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.974881: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
models_model_host.1.rnmmwpelij0w@box    | pciBusID: 0000:0a:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
models_model_host.1.rnmmwpelij0w@box    | pciBusID: 0000:0a:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
models_model_host.1.rnmmwpelij0w@box    | coreClock: 1.4805GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s
models_model_host.1.rnmmwpelij0w@box    | coreClock: 1.4805GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.974898: I external/org_tensorflow/tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.974898: I external/org_tensorflow/tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.974942: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.974942: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.975190: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.975190: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.975418: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.975418: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.975448: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.975448: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.975457: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.975457: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.975465: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.975465: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.975528: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.975528: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.975777: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.975777: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.976006: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 120 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1)
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.976006: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 120 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1)
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.976166: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.976166: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.976559: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.976559: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
models_model_host.1.rnmmwpelij0w@box    | pciBusID: 0000:0a:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
models_model_host.1.rnmmwpelij0w@box    | pciBusID: 0000:0a:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
models_model_host.1.rnmmwpelij0w@box    | coreClock: 1.4805GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s
models_model_host.1.rnmmwpelij0w@box    | coreClock: 1.4805GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.976628: I external/org_tensorflow/tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.976628: I external/org_tensorflow/tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.976682: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.976682: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.977032: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.977032: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.977355: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.977355: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.977398: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.977398: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.977412: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.977412: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.977419: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.977419: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.977557: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.977557: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.977921: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.977921: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.978247: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 120 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1)
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:33.978247: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 120 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1)
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.061933: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.061933: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.070443: I external/org_tensorflow/tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3592785000 Hz
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.070443: I external/org_tensorflow/tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3592785000 Hz
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.077451: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.077451: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.087849: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.087849: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.155287: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /models/ZILBNB_export/1610136569
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.155287: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /models/ZILBNB_export/1610136569
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.175977: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /best_exported_models/ZILBNB/1
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.175977: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /best_exported_models/ZILBNB/1
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.186600: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 720312 microseconds.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.186600: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 720312 microseconds.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.190483: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /models/ZILBNB_export/1610136569/assets.extra/tf_serving_warmup_requests
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.190483: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /models/ZILBNB_export/1610136569/assets.extra/tf_serving_warmup_requests
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.194006: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: ZILBNB version: 1610136569}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.194006: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: ZILBNB version: 1610136569}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.197239: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 932770 microseconds.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.197239: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 932770 microseconds.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.199518: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /best_exported_models/ZILBNB/1/assets.extra/tf_serving_warmup_requests
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.199518: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /best_exported_models/ZILBNB/1/assets.extra/tf_serving_warmup_requests
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.201636: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: best_ZILBNB version: 1}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.201636: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: best_ZILBNB version: 1}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.207148: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /models/ZILBNB_export/1610136623
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.207148: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /models/ZILBNB_export/1610136623
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.229573: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 864825 microseconds.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.229573: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 864825 microseconds.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.231886: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /models/ZILBNB_export/1610136623/assets.extra/tf_serving_warmup_requests
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.231886: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /models/ZILBNB_export/1610136623/assets.extra/tf_serving_warmup_requests
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.234286: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: ZILBNB version: 1610136623}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.234286: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: ZILBNB version: 1610136623}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.239162: I tensorflow_serving/model_servers/server.cc:371] Running gRPC ModelServer at 0.0.0.0:8500 ...
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.239162: I tensorflow_serving/model_servers/server.cc:371] Running gRPC ModelServer at 0.0.0.0:8500 ...
models_model_host.1.rnmmwpelij0w@box    | [warn] getaddrinfo: address family for nodename not supported
models_model_host.1.rnmmwpelij0w@box    | [warn] getaddrinfo: address family for nodename not supported
models_model_host.1.rnmmwpelij0w@box    | [evhttp_server.cc : 238] NET_LOG: Entering the event loop ...
models_model_host.1.rnmmwpelij0w@box    | [evhttp_server.cc : 238] NET_LOG: Entering the event loop ...
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.248747: I tensorflow_serving/model_servers/server.cc:391] Exporting HTTP/REST API at:localhost:8501 ...
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:34.248747: I tensorflow_serving/model_servers/server.cc:391] Exporting HTTP/REST API at:localhost:8501 ...
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:37.882616: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 403.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:37.882616: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 403.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:37.913142: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 532.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:37.913142: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 532.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:37.922715: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 790.01MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:37.922715: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 790.01MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:37.931163: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 790.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:37.931163: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 790.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:37.939827: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:37.939827: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.181561: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: ZILBNB version: 1610136637}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.181601: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: ZILBNB version: 1610136637}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.181561: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: ZILBNB version: 1610136637}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.181601: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: ZILBNB version: 1610136637}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.181612: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: ZILBNB version: 1610136637}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.181612: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: ZILBNB version: 1610136637}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.181641: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: /models/ZILBNB_export/1610136637
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.181641: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: /models/ZILBNB_export/1610136637
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.190696: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.190696: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.190740: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: /models/ZILBNB_export/1610136637
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.190740: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: /models/ZILBNB_export/1610136637
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.190887: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.190887: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.216017: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.216017: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
models_model_host.1.rnmmwpelij0w@box    | pciBusID: 0000:0a:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
models_model_host.1.rnmmwpelij0w@box    | pciBusID: 0000:0a:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
models_model_host.1.rnmmwpelij0w@box    | coreClock: 1.4805GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s
models_model_host.1.rnmmwpelij0w@box    | coreClock: 1.4805GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.216060: I external/org_tensorflow/tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.216060: I external/org_tensorflow/tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.216152: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.216152: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.216603: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.216603: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.216970: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.216970: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.217011: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.217011: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.217021: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.217021: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.217027: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.217027: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.217107: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.217107: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.217537: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.217537: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.218051: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 120 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1)
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.218051: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 120 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1)
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.256621: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.256621: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.333129: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /models/ZILBNB_export/1610136637
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.333129: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /models/ZILBNB_export/1610136637
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.349785: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 168144 microseconds.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.349785: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 168144 microseconds.
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.352222: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /models/ZILBNB_export/1610136637/assets.extra/tf_serving_warmup_requests
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.352222: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /models/ZILBNB_export/1610136637/assets.extra/tf_serving_warmup_requests
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.354841: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: ZILBNB version: 1610136637}
models_model_host.1.rnmmwpelij0w@box    | 2021-01-08 20:10:39.354841: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: ZILBNB version: 1610136637}
